,n_epochs,avg_epoch_time,test_loss,test_accuracy,test_recall,test_precision,test_AUC,model,training_time
0,9,6.229607317182753,0.5260695219039917,0.7337662577629089,0.6165803074836731,0.7083333134651184,0.8110734224319458,"LSTM with pre-trained embeddings (wiki gigaword 200), No Regularisation",
1,9,6.162976768281725,0.6209320425987244,0.7229437232017517,0.6113989353179932,0.6900584697723389,0.8029065132141113,"LSTM with pre-trained embeddings (wiki gigaword 200), Regularisation (dropoute 0.2, L2 0.001)",
2,8,4.390950620174408,0.5169242024421692,0.7294372320175171,0.7409326434135437,0.6559633016586304,0.8198856115341187,"LSTM with pre-trained embeddings (wiki gigaword 200), Regularisation (dropoute 0.2)",
3,9,5.441832913292779,0.5260695219039917,0.7337662577629089,0.6165803074836731,0.7083333134651184,0.8110734224319458,"LSTM with pre-trained embeddings (wiki gigaword 200), No Regularisation",48.97649621963501
4,9,4.801295889748467,0.6209320425987244,0.7229437232017517,0.6113989353179932,0.6900584697723389,0.8029065132141113,"LSTM with pre-trained embeddings (wiki gigaword 200), Regularisation (dropoute 0.2, L2 0.001)",43.211663007736206
5,8,4.274232119321823,0.5169242024421692,0.7294372320175171,0.7409326434135437,0.6559633016586304,0.8198856115341187,"LSTM with pre-trained embeddings (wiki gigaword 200), Regularisation (dropoute 0.2)",34.193856954574585
6,8,6.774423748254776,0.4644244015216827,0.7878788113594055,0.7564767003059387,0.7411167621612549,0.8701484799385071,Bidirectional LSTM with pre-trained embeddings (wiki gigaword 200),54.19538998603821
7,8,7.427709013223648,0.5874052047729492,0.7878788113594055,0.7202072739601135,0.7595628499984741,0.8750312924385071,"Bidirectional LSTM with pre-trained embeddings (wiki gigaword 200), Regularisation (dropout 0.2, L2 0.001)",59.42167210578919
8,8,18.47057384252548,0.4327661395072937,0.8138527870178223,0.7305699586868286,0.8057143092155457,0.88272625207901,"Bidirectional LSTM with pre-trained embeddings (wiki gigaword 200), 2 layers, 64 neurons, Batch Normalisation",147.76459074020386
9,7,8.429358312061854,0.4310497045516968,0.8116883039474487,0.7979274392127991,0.7623762488365173,0.8813972473144531,Bidirectional LSTM with pre-trained embeddings (wiki gigaword 300),59.00550818443298
10,7,10.448230573109218,0.5124505758285522,0.7467532753944397,0.6632124185562134,0.7111111283302307,0.8212724328041077,"One Layer RNN (32), No Regularisation, Embeddings size: 200",73.13761401176453
11,8,17.47434711456299,0.7827199101448059,0.5909090638160706,0.5025906562805176,0.5105262994766235,0.6367567181587219,"One Layer RNN (128), No Regularisation, Embeddings size: 200, RNN units: 128",139.7947769165039
12,7,13.562725986753192,0.5369167923927307,0.8571428656578064,0.8445596098899841,0.8190954923629761,0.9017758965492249,"One Layer RNN (32), Regularisation, Embeddings size: 200",94.93908190727234
13,7,7.309019429343087,0.7822411060333252,0.6904761791229248,0.393782377243042,0.7450980544090271,0.7713080644607544,"One Layer RNN (32), Regularisation, Batch Normalization, Embeddings size: 200",51.16313600540161
14,7,9.771114587783812,0.5748891830444336,0.7532467246055603,0.772020697593689,0.6803653240203857,0.8125662207603455,"Two Layer RNN (32), No Regularisation, Embeddings size: 200",68.3978021144867
15,7,12.819992576326642,0.9755025506019592,0.673160195350647,0.6113989353179932,0.6082473993301392,0.7099601626396179,"Two Layer RNN (32), Regularisation, Embeddings size: 200",89.7399480342865
16,7,13.546786853245326,0.8662327527999878,0.7359307408332825,0.590673565864563,0.7261146306991577,0.8073945045471191,"Two Layer RNN (32), Regularisation, Batch Normalization, Embeddings size: 200",94.82750797271729
17,7,11.501918145588466,0.4600655138492584,0.8441558480262756,0.8134714961051941,0.8134714961051941,0.9004276394844055,"One Layer LSTM (32), No Regularisation, Embeddings size: 200",80.51342701911926
18,7,11.058178561074394,0.5834680199623108,0.8181818127632141,0.7564767003059387,0.7978141903877258,0.8979043364524841,"One Layer LSTM (32), Regularisation, Embeddings size: 200",77.40724992752075
19,8,10.8918459713459,0.5094902515411377,0.8008658289909363,0.7357512712478638,0.7759562730789185,0.8939364552497864,"One Layer LSTM (32), Regularisation, Batch Normalization, Embeddings size: 200",87.13476777076721
20,7,19.872403144836422,0.5897271633148193,0.7813853025436401,0.5284973978996277,0.9107142686843872,0.8943024277687073,"One Layer LSTM (128), Regularisation, Batch Normalization, Embeddings size: 200, LSTM units: 128",139.10682201385498
21,7,15.378952843802317,0.6135527491569519,0.8160173296928406,0.7512953281402588,0.7967032790184021,0.8966619372367859,"Two Layer LSTM (32), No Regularisation, Embeddings size: 200",107.6526699066162
22,7,16.511810166495188,0.6639440059661865,0.8051947951316833,0.7150259017944336,0.7976878881454468,0.8959493041038513,"Two Layer LSTM (32), Regularisation, Embeddings size: 200",115.58267116546632
23,11,22.56583907387473,0.6431843638420105,0.8095238208770752,0.6476684212684631,0.8620689511299133,0.885991096496582,"Two Layer LSTM (64), Regularisation, Batch Normalization, Embeddings size: 200",248.22422981262207
24,8,46.87447512149811,0.7311426997184753,0.7878788113594055,0.6943005323410034,0.7745664715766907,0.8802800178527832,"Three Layer LSTM (128), Regularisation, Embeddings size: 200",374.99580097198486
25,10,31.774855303764344,0.7583655714988708,0.7597402334213257,0.49740931391716,0.8727272748947144,0.8695706725120544,"Three Layer LSTM (128), Regularisation, Embeddings size: 200",317.74855303764343
26,7,10.40233428137643,0.4572385847568512,0.8571428656578064,0.8134714961051941,0.8395721912384033,0.9220004081726074,"One Layer Bidirectional LSTM (32), No Regularisation, Embeddings size: 200",72.81633996963501
27,7,12.820851564407349,0.5334736704826355,0.8484848737716675,0.9119170904159546,0.7685589790344238,0.9289924502372742,"One Layer Bidirectional LSTM (32), Regularisation, Embeddings size: 200",89.74596095085144
28,15,149.3480315367381,0.4785975217819214,0.8558558821678162,0.9650349617004395,0.7624309659004211,0.9545637965202332,"[PseudoL] One Layer Bidirectional LSTM (32), No Regularisation, Embeddings size: 200",2240.220473051071
29,7,129.47295713424683,0.531086802482605,0.8768768906593323,0.9860140085220337,0.7833333611488342,0.9483069181442261,"[PseudoL] Bidirectional LSTM with 1 layer, 32 units, 200 embedding dim, no dropout, no l2 regularization",906.3106999397278
